{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs related to image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs related to machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [180, 180])\n",
    "    image = image / 255.0 # normalize pixel values\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('./images/')\n",
    "images = data_dir.glob('*.jpg')\n",
    "image_count = len(list(images))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# load the images path, data and labels\n",
    "data = json.load(open('./images/_annotations.json'))\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "images_data = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    image_path = os.path.join(data_dir, filename)\n",
    "    if os.path.isfile(image_path) and (filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('jpeg')):\n",
    "        image_paths.append(image_path)\n",
    "        label = data['annotations'][filename][0]['label']\n",
    "        labels.append(label)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (50, 50))\n",
    "        images_data.append(image)\n",
    "        \n",
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images data\n",
    "data = np.array(images_data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training and testing data\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 50, 50, 3)\n",
      "(10, 50, 50, 3)\n",
      "(90,)\n",
      "(10,)\n",
      "[[[[0.81568627 0.76078431 0.76470588]\n",
      "   [0.80392157 0.74901961 0.77254902]\n",
      "   [0.79215686 0.74117647 0.78039216]\n",
      "   ...\n",
      "   [0.00392157 0.02352941 0.2627451 ]\n",
      "   [0.00392157 0.02745098 0.25882353]\n",
      "   [0.00784314 0.02352941 0.24705882]]\n",
      "\n",
      "  [[0.80392157 0.74117647 0.78039216]\n",
      "   [0.78431373 0.72156863 0.76470588]\n",
      "   [0.8        0.73333333 0.77647059]\n",
      "   ...\n",
      "   [0.01568627 0.03137255 0.28627451]\n",
      "   [0.01568627 0.03137255 0.27843137]\n",
      "   [0.01568627 0.03921569 0.26666667]]\n",
      "\n",
      "  [[0.79215686 0.72156863 0.77254902]\n",
      "   [0.81176471 0.74117647 0.79215686]\n",
      "   [0.81176471 0.74509804 0.79215686]\n",
      "   ...\n",
      "   [0.00392157 0.01960784 0.23137255]\n",
      "   [0.00392157 0.02745098 0.23529412]\n",
      "   [0.00392157 0.02352941 0.23529412]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43529412 0.44705882 0.7372549 ]\n",
      "   [0.42745098 0.44313725 0.7372549 ]\n",
      "   [0.40392157 0.41960784 0.7254902 ]\n",
      "   ...\n",
      "   [0.27058824 0.45098039 0.96862745]\n",
      "   [0.19215686 0.34117647 0.8627451 ]\n",
      "   [0.19215686 0.31764706 0.81960784]]\n",
      "\n",
      "  [[0.42352941 0.45882353 0.74901961]\n",
      "   [0.4        0.43921569 0.74117647]\n",
      "   [0.38039216 0.41960784 0.73333333]\n",
      "   ...\n",
      "   [0.28235294 0.48627451 0.97647059]\n",
      "   [0.2        0.36862745 0.87058824]\n",
      "   [0.19215686 0.3254902  0.81176471]]\n",
      "\n",
      "  [[0.40784314 0.45490196 0.76078431]\n",
      "   [0.4        0.45490196 0.76470588]\n",
      "   [0.37254902 0.43137255 0.75294118]\n",
      "   ...\n",
      "   [0.28235294 0.49803922 1.        ]\n",
      "   [0.20392157 0.38823529 0.90196078]\n",
      "   [0.18039216 0.31764706 0.80784314]]]\n",
      "\n",
      "\n",
      " [[[0.51372549 0.45490196 0.43137255]\n",
      "   [0.1372549  0.09803922 0.08627451]\n",
      "   [0.11764706 0.09803922 0.08235294]\n",
      "   ...\n",
      "   [0.02745098 0.04705882 0.01176471]\n",
      "   [0.02352941 0.04313725 0.00784314]\n",
      "   [0.03529412 0.04705882 0.01176471]]\n",
      "\n",
      "  [[0.85490196 0.72941176 0.70980392]\n",
      "   [0.83137255 0.7254902  0.71764706]\n",
      "   [0.62745098 0.55294118 0.55686275]\n",
      "   ...\n",
      "   [0.02352941 0.04313725 0.00784314]\n",
      "   [0.02352941 0.04313725 0.00784314]\n",
      "   [0.03137255 0.03921569 0.00392157]]\n",
      "\n",
      "  [[0.80392157 0.7254902  0.72941176]\n",
      "   [0.83529412 0.72941176 0.74117647]\n",
      "   [0.8627451  0.74117647 0.75686275]\n",
      "   ...\n",
      "   [0.03137255 0.04705882 0.02352941]\n",
      "   [0.01960784 0.03529412 0.01176471]\n",
      "   [0.02745098 0.03529412 0.01176471]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.70980392 0.53333333 0.54509804]\n",
      "   [0.74509804 0.56470588 0.61176471]\n",
      "   [0.24313725 0.13333333 0.48627451]\n",
      "   ...\n",
      "   [0.07058824 0.09019608 0.05490196]\n",
      "   [0.08235294 0.10196078 0.06666667]\n",
      "   [0.09411765 0.10588235 0.0627451 ]]\n",
      "\n",
      "  [[0.83921569 0.60784314 0.64313725]\n",
      "   [0.4        0.22352941 0.57647059]\n",
      "   [0.23921569 0.11764706 0.61176471]\n",
      "   ...\n",
      "   [0.08235294 0.09803922 0.05490196]\n",
      "   [0.08235294 0.10588235 0.0627451 ]\n",
      "   [0.09803922 0.10588235 0.05882353]]\n",
      "\n",
      "  [[0.36862745 0.17647059 0.60784314]\n",
      "   [0.35686275 0.15686275 0.66666667]\n",
      "   [0.28235294 0.17254902 0.64705882]\n",
      "   ...\n",
      "   [0.07843137 0.09803922 0.05882353]\n",
      "   [0.08627451 0.10196078 0.05490196]\n",
      "   [0.10980392 0.10980392 0.05098039]]]\n",
      "\n",
      "\n",
      " [[[0.01176471 0.03137255 0.03529412]\n",
      "   [0.01960784 0.03529412 0.03137255]\n",
      "   [0.01568627 0.03921569 0.03529412]\n",
      "   ...\n",
      "   [0.09411765 0.08235294 0.12941176]\n",
      "   [0.10588235 0.07843137 0.10980392]\n",
      "   [0.08235294 0.0627451  0.08627451]]\n",
      "\n",
      "  [[0.01960784 0.04313725 0.04705882]\n",
      "   [0.02745098 0.04705882 0.05098039]\n",
      "   [0.03529412 0.05882353 0.07843137]\n",
      "   ...\n",
      "   [0.0627451  0.09019608 0.1254902 ]\n",
      "   [0.10980392 0.11372549 0.12941176]\n",
      "   [0.08627451 0.09411765 0.10980392]]\n",
      "\n",
      "  [[0.02745098 0.0627451  0.06666667]\n",
      "   [0.03529412 0.06666667 0.0745098 ]\n",
      "   [0.05098039 0.09411765 0.12156863]\n",
      "   ...\n",
      "   [0.04705882 0.08627451 0.1372549 ]\n",
      "   [0.07843137 0.09411765 0.1254902 ]\n",
      "   [0.08627451 0.09411765 0.1254902 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3372549  0.60392157 0.78431373]\n",
      "   [0.17647059 0.39607843 0.58823529]\n",
      "   [0.2627451  0.46666667 0.61960784]\n",
      "   ...\n",
      "   [0.03529412 0.12941176 0.3254902 ]\n",
      "   [0.05882353 0.14901961 0.30980392]\n",
      "   [0.03921569 0.10980392 0.25098039]]\n",
      "\n",
      "  [[0.24313725 0.52156863 0.74117647]\n",
      "   [0.29019608 0.50980392 0.72941176]\n",
      "   [0.15686275 0.40392157 0.63529412]\n",
      "   ...\n",
      "   [0.0627451  0.13333333 0.3372549 ]\n",
      "   [0.02745098 0.10196078 0.28235294]\n",
      "   [0.11764706 0.2        0.37647059]]\n",
      "\n",
      "  [[0.31764706 0.50196078 0.70588235]\n",
      "   [0.23137255 0.39607843 0.57254902]\n",
      "   [0.1372549  0.36862745 0.56470588]\n",
      "   ...\n",
      "   [0.03529412 0.10980392 0.29411765]\n",
      "   [0.01960784 0.07843137 0.21568627]\n",
      "   [0.0745098  0.12941176 0.28235294]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.10588235 0.20392157]\n",
      "   [0.04705882 0.10196078 0.18431373]\n",
      "   [0.09019608 0.11764706 0.18431373]\n",
      "   ...\n",
      "   [0.95294118 0.80392157 0.64313725]\n",
      "   [0.97254902 0.82352941 0.65490196]\n",
      "   [0.96470588 0.83137255 0.6627451 ]]\n",
      "\n",
      "  [[0.0745098  0.10980392 0.21568627]\n",
      "   [0.03137255 0.08627451 0.18823529]\n",
      "   [0.01176471 0.09803922 0.2       ]\n",
      "   ...\n",
      "   [0.94509804 0.8        0.65098039]\n",
      "   [0.96470588 0.82352941 0.66666667]\n",
      "   [0.97254902 0.83529412 0.67843137]]\n",
      "\n",
      "  [[0.18823529 0.31764706 0.43529412]\n",
      "   [0.08627451 0.14509804 0.2745098 ]\n",
      "   [0.14117647 0.19215686 0.32156863]\n",
      "   ...\n",
      "   [0.94901961 0.8        0.6627451 ]\n",
      "   [0.96470588 0.82352941 0.66666667]\n",
      "   [0.96862745 0.83137255 0.6627451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43137255 0.44313725 0.47058824]\n",
      "   [0.36470588 0.41176471 0.45098039]\n",
      "   [0.3372549  0.4        0.45098039]\n",
      "   ...\n",
      "   [0.69019608 0.60784314 0.5254902 ]\n",
      "   [0.70980392 0.61568627 0.5372549 ]\n",
      "   [0.72156863 0.63137255 0.56862745]]\n",
      "\n",
      "  [[0.4745098  0.49411765 0.52156863]\n",
      "   [0.4745098  0.50980392 0.55294118]\n",
      "   [0.41568627 0.4745098  0.5254902 ]\n",
      "   ...\n",
      "   [0.69019608 0.61176471 0.54117647]\n",
      "   [0.70196078 0.62745098 0.56078431]\n",
      "   [0.71372549 0.62352941 0.56078431]]\n",
      "\n",
      "  [[0.58823529 0.63137255 0.69019608]\n",
      "   [0.54117647 0.57647059 0.64313725]\n",
      "   [0.49019608 0.5372549  0.60784314]\n",
      "   ...\n",
      "   [0.68627451 0.61176471 0.54901961]\n",
      "   [0.69411765 0.61960784 0.56470588]\n",
      "   [0.70196078 0.62352941 0.55686275]]]\n",
      "\n",
      "\n",
      " [[[0.01960784 0.01568627 0.02352941]\n",
      "   [0.01960784 0.01960784 0.01960784]\n",
      "   [0.01176471 0.00784314 0.02745098]\n",
      "   ...\n",
      "   [0.00392157 0.01960784 0.05490196]\n",
      "   [0.         0.00784314 0.05882353]\n",
      "   [0.00392157 0.01568627 0.0745098 ]]\n",
      "\n",
      "  [[0.01960784 0.01568627 0.02745098]\n",
      "   [0.01568627 0.01568627 0.01568627]\n",
      "   [0.01568627 0.01176471 0.01960784]\n",
      "   ...\n",
      "   [0.03137255 0.01176471 0.02745098]\n",
      "   [0.04313725 0.02352941 0.03921569]\n",
      "   [0.03921569 0.02745098 0.04313725]]\n",
      "\n",
      "  [[0.01960784 0.01176471 0.03529412]\n",
      "   [0.01960784 0.01176471 0.03137255]\n",
      "   [0.01960784 0.01568627 0.02352941]\n",
      "   ...\n",
      "   [0.02745098 0.01568627 0.03529412]\n",
      "   [0.03137255 0.01960784 0.03137255]\n",
      "   [0.05882353 0.03921569 0.05098039]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02352941 0.01960784 0.02745098]\n",
      "   [0.01960784 0.01568627 0.02352941]\n",
      "   [0.02352941 0.01960784 0.02745098]\n",
      "   ...\n",
      "   [0.21960784 0.2        0.35294118]\n",
      "   [0.21568627 0.2        0.36078431]\n",
      "   [0.2        0.18431373 0.34509804]]\n",
      "\n",
      "  [[0.02352941 0.01960784 0.02745098]\n",
      "   [0.01568627 0.01176471 0.01960784]\n",
      "   [0.01960784 0.01568627 0.02352941]\n",
      "   ...\n",
      "   [0.21960784 0.2        0.35294118]\n",
      "   [0.21568627 0.2        0.36078431]\n",
      "   [0.21176471 0.18823529 0.34509804]]\n",
      "\n",
      "  [[0.02745098 0.01568627 0.02352941]\n",
      "   [0.01568627 0.01176471 0.01960784]\n",
      "   [0.01568627 0.01176471 0.01960784]\n",
      "   ...\n",
      "   [0.23529412 0.2        0.35686275]\n",
      "   [0.21960784 0.20784314 0.36078431]\n",
      "   [0.20392157 0.19215686 0.34117647]]]]\n",
      "[[[[0.20784314 0.2        0.19215686]\n",
      "   [0.20784314 0.20392157 0.2       ]\n",
      "   [0.19607843 0.20392157 0.20392157]\n",
      "   ...\n",
      "   [0.36078431 0.36862745 0.41176471]\n",
      "   [0.44313725 0.44313725 0.49019608]\n",
      "   [0.54901961 0.54901961 0.6       ]]\n",
      "\n",
      "  [[0.18431373 0.19215686 0.19607843]\n",
      "   [0.19215686 0.19215686 0.2       ]\n",
      "   [0.20784314 0.20784314 0.21568627]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.40392157]\n",
      "   [0.33333333 0.3372549  0.39215686]\n",
      "   [0.55294118 0.54117647 0.59215686]]\n",
      "\n",
      "  [[0.17647059 0.2        0.21568627]\n",
      "   [0.17647059 0.19607843 0.21568627]\n",
      "   [0.19607843 0.21176471 0.23137255]\n",
      "   ...\n",
      "   [0.35686275 0.36862745 0.42745098]\n",
      "   [0.36862745 0.37254902 0.42745098]\n",
      "   [0.3372549  0.31764706 0.36470588]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.80392157 0.80784314 0.84705882]\n",
      "   [0.69411765 0.72941176 0.77647059]\n",
      "   [0.71764706 0.76078431 0.81568627]\n",
      "   ...\n",
      "   [0.30980392 0.24313725 0.21568627]\n",
      "   [0.27843137 0.21960784 0.19215686]\n",
      "   [0.23137255 0.18431373 0.16078431]]\n",
      "\n",
      "  [[0.14117647 0.10980392 0.15294118]\n",
      "   [0.8627451  0.85490196 0.89019608]\n",
      "   [0.80784314 0.83529412 0.87058824]\n",
      "   ...\n",
      "   [0.27058824 0.23137255 0.20392157]\n",
      "   [0.29019608 0.25098039 0.22352941]\n",
      "   [0.27058824 0.23137255 0.19215686]]\n",
      "\n",
      "  [[0.09019608 0.08627451 0.11764706]\n",
      "   [0.14117647 0.10588235 0.16078431]\n",
      "   [0.50588235 0.50196078 0.54901961]\n",
      "   ...\n",
      "   [0.29411765 0.25882353 0.21176471]\n",
      "   [0.29411765 0.25882353 0.23137255]\n",
      "   [0.27843137 0.25098039 0.2       ]]]\n",
      "\n",
      "\n",
      " [[[0.80392157 0.83529412 0.80784314]\n",
      "   [0.81568627 0.83921569 0.8       ]\n",
      "   [0.8        0.84313725 0.80392157]\n",
      "   ...\n",
      "   [0.69803922 0.77254902 0.76470588]\n",
      "   [0.69411765 0.77254902 0.76078431]\n",
      "   [0.68235294 0.76470588 0.76078431]]\n",
      "\n",
      "  [[0.83137255 0.85882353 0.82352941]\n",
      "   [0.84313725 0.85882353 0.81568627]\n",
      "   [0.82352941 0.8627451  0.81568627]\n",
      "   ...\n",
      "   [0.72941176 0.78823529 0.77254902]\n",
      "   [0.71764706 0.79215686 0.77254902]\n",
      "   [0.69019608 0.78039216 0.76862745]]\n",
      "\n",
      "  [[0.85490196 0.87058824 0.83529412]\n",
      "   [0.8627451  0.8745098  0.82352941]\n",
      "   [0.85490196 0.88627451 0.83529412]\n",
      "   ...\n",
      "   [0.7372549  0.8        0.77254902]\n",
      "   [0.72941176 0.80392157 0.78431373]\n",
      "   [0.70588235 0.79215686 0.78823529]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.64705882 0.6627451  0.81176471]\n",
      "   [0.70588235 0.72156863 0.85882353]\n",
      "   [0.64313725 0.6745098  0.82745098]\n",
      "   ...\n",
      "   [0.85882353 0.94117647 0.9254902 ]\n",
      "   [0.86666667 0.95294118 0.94117647]\n",
      "   [0.87843137 0.96470588 0.96078431]]\n",
      "\n",
      "  [[0.78039216 0.77254902 0.83921569]\n",
      "   [0.64313725 0.62745098 0.73333333]\n",
      "   [0.31372549 0.30196078 0.51372549]\n",
      "   ...\n",
      "   [0.85490196 0.9372549  0.9254902 ]\n",
      "   [0.8627451  0.94509804 0.93333333]\n",
      "   [0.8627451  0.94901961 0.95294118]]\n",
      "\n",
      "  [[0.79215686 0.76470588 0.81960784]\n",
      "   [0.80784314 0.79215686 0.81176471]\n",
      "   [0.77254902 0.76862745 0.83921569]\n",
      "   ...\n",
      "   [0.83921569 0.92156863 0.91372549]\n",
      "   [0.84313725 0.9254902  0.91764706]\n",
      "   [0.84313725 0.9372549  0.9372549 ]]]\n",
      "\n",
      "\n",
      " [[[0.79215686 0.61960784 0.00392157]\n",
      "   [0.83137255 0.68627451 0.02352941]\n",
      "   [0.85098039 0.70588235 0.02352941]\n",
      "   ...\n",
      "   [0.50980392 0.61568627 0.67058824]\n",
      "   [0.51764706 0.6        0.66666667]\n",
      "   [0.50196078 0.62352941 0.69019608]]\n",
      "\n",
      "  [[0.67058824 0.54509804 0.03529412]\n",
      "   [0.64313725 0.5254902  0.08235294]\n",
      "   [0.72156863 0.59215686 0.22745098]\n",
      "   ...\n",
      "   [0.55686275 0.6627451  0.70196078]\n",
      "   [0.54901961 0.65490196 0.70588235]\n",
      "   [0.4745098  0.57254902 0.63921569]]\n",
      "\n",
      "  [[0.78039216 0.6627451  0.34509804]\n",
      "   [0.76078431 0.68235294 0.34117647]\n",
      "   [0.76470588 0.67058824 0.38823529]\n",
      "   ...\n",
      "   [0.21568627 0.27058824 0.34117647]\n",
      "   [0.20784314 0.2627451  0.33333333]\n",
      "   [0.31372549 0.35294118 0.41568627]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.4745098  0.49803922 0.58039216]\n",
      "   [0.48627451 0.51372549 0.58823529]\n",
      "   [0.49019608 0.51764706 0.59215686]\n",
      "   ...\n",
      "   [0.50980392 0.55294118 0.60784314]\n",
      "   [0.50588235 0.54509804 0.61176471]\n",
      "   [0.50588235 0.5372549  0.60392157]]\n",
      "\n",
      "  [[0.45882353 0.48627451 0.56078431]\n",
      "   [0.47843137 0.50588235 0.57254902]\n",
      "   [0.49411765 0.52156863 0.57647059]\n",
      "   ...\n",
      "   [0.51764706 0.55294118 0.60784314]\n",
      "   [0.49803922 0.54117647 0.59607843]\n",
      "   [0.49019608 0.52941176 0.58823529]]\n",
      "\n",
      "  [[0.43921569 0.47843137 0.54509804]\n",
      "   [0.45882353 0.50588235 0.55686275]\n",
      "   [0.47058824 0.50588235 0.55686275]\n",
      "   ...\n",
      "   [0.49019608 0.5254902  0.58039216]\n",
      "   [0.4745098  0.51764706 0.57254902]\n",
      "   [0.46666667 0.50980392 0.56470588]]]\n",
      "\n",
      "\n",
      " [[[0.01568627 0.01176471 0.01176471]\n",
      "   [0.02745098 0.00784314 0.01568627]\n",
      "   [0.00392157 0.01176471 0.05098039]\n",
      "   ...\n",
      "   [0.99607843 1.         0.98823529]\n",
      "   [1.         1.         0.99607843]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.21176471 0.22745098 0.32156863]\n",
      "   [0.26666667 0.33333333 0.35686275]\n",
      "   [0.8        0.88235294 0.96470588]\n",
      "   ...\n",
      "   [0.98039216 0.99215686 1.        ]\n",
      "   [0.98823529 0.99607843 0.99607843]\n",
      "   [0.98431373 1.         0.99215686]]\n",
      "\n",
      "  [[0.7372549  0.80392157 0.91372549]\n",
      "   [0.89803922 0.96078431 0.99607843]\n",
      "   [0.97254902 0.99215686 0.98431373]\n",
      "   ...\n",
      "   [0.58823529 0.57647059 0.66666667]\n",
      "   [0.82352941 0.81568627 0.8627451 ]\n",
      "   [0.96862745 0.98431373 0.99215686]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.71764706 0.81960784 0.99215686]\n",
      "   [0.74509804 0.81568627 0.98039216]\n",
      "   [0.75294118 0.82745098 0.98823529]\n",
      "   ...\n",
      "   [0.75686275 0.78039216 0.96470588]\n",
      "   [0.78823529 0.78823529 0.98431373]\n",
      "   [0.78431373 0.78823529 0.96078431]]\n",
      "\n",
      "  [[0.67843137 0.78039216 0.96470588]\n",
      "   [0.70980392 0.8        0.97647059]\n",
      "   [0.72941176 0.81568627 0.97647059]\n",
      "   ...\n",
      "   [0.78431373 0.80784314 0.99607843]\n",
      "   [0.79215686 0.79607843 0.99215686]\n",
      "   [0.77647059 0.77647059 0.96078431]]\n",
      "\n",
      "  [[0.65490196 0.76078431 0.94509804]\n",
      "   [0.67843137 0.78823529 0.95686275]\n",
      "   [0.72941176 0.82745098 0.98431373]\n",
      "   ...\n",
      "   [0.75686275 0.76862745 0.96470588]\n",
      "   [0.77254902 0.78431373 0.98431373]\n",
      "   [0.74509804 0.75686275 0.95686275]]]\n",
      "\n",
      "\n",
      " [[[0.05882353 0.12156863 0.38039216]\n",
      "   [0.04313725 0.10588235 0.36862745]\n",
      "   [0.04705882 0.1254902  0.35686275]\n",
      "   ...\n",
      "   [0.00784314 0.05490196 0.16078431]\n",
      "   [0.03529412 0.03529412 0.11372549]\n",
      "   [0.01568627 0.04313725 0.18431373]]\n",
      "\n",
      "  [[0.05882353 0.11372549 0.34509804]\n",
      "   [0.05882353 0.11372549 0.34117647]\n",
      "   [0.06666667 0.13333333 0.34117647]\n",
      "   ...\n",
      "   [0.03137255 0.06666667 0.16862745]\n",
      "   [0.01568627 0.02745098 0.10980392]\n",
      "   [0.04313725 0.08627451 0.24313725]]\n",
      "\n",
      "  [[0.06666667 0.12941176 0.3372549 ]\n",
      "   [0.07843137 0.12941176 0.33333333]\n",
      "   [0.07058824 0.12941176 0.32156863]\n",
      "   ...\n",
      "   [0.02745098 0.04313725 0.15686275]\n",
      "   [0.01960784 0.04313725 0.14509804]\n",
      "   [0.03137255 0.08235294 0.28627451]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.1254902  0.14509804 0.22745098]\n",
      "   [0.14509804 0.16862745 0.24313725]\n",
      "   [0.14901961 0.16862745 0.23921569]\n",
      "   ...\n",
      "   [0.16862745 0.19607843 0.20784314]\n",
      "   [0.10980392 0.13333333 0.16078431]\n",
      "   [0.03137255 0.04313725 0.0627451 ]]\n",
      "\n",
      "  [[0.10196078 0.15294118 0.22745098]\n",
      "   [0.14117647 0.16078431 0.25098039]\n",
      "   [0.15686275 0.16862745 0.24313725]\n",
      "   ...\n",
      "   [0.0745098  0.10196078 0.11372549]\n",
      "   [0.01176471 0.02352941 0.04313725]\n",
      "   [0.01176471 0.01960784 0.05098039]]\n",
      "\n",
      "  [[0.13333333 0.17254902 0.25098039]\n",
      "   [0.1254902  0.15294118 0.26666667]\n",
      "   [0.14509804 0.16078431 0.25490196]\n",
      "   ...\n",
      "   [0.00784314 0.02745098 0.02352941]\n",
      "   [0.00392157 0.01960784 0.02352941]\n",
      "   [0.00392157 0.01960784 0.03921569]]]]\n",
      "['hotdog' 'hotdog' 'not_hotdog' 'not_hotdog' 'not_hotdog']\n",
      "['hotdog' 'hotdog' 'not_hotdog' 'not_hotdog' 'not_hotdog']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X_train[:5])  # Print the first 5 samples from the train features\n",
    "print(X_test[:5])   # Print the first 5 samples from the test features\n",
    "print(y_train[:5])  # Print the first 5 samples from the train labels\n",
    "print(y_test[:5])   # Print the first 5 samples from the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    # CONV => RELU => POOL\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(50, 50, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # (CONV => RELU => POOL) * 2\n",
    "    layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # (CONV => RELU => POOL) * 3\n",
    "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    # softmax classifier\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer ='adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta = 0.01,\n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9667WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0495 - accuracy: 0.9667\n",
      "Epoch 2/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 355ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 3/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9778WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 360ms/step - loss: 0.0353 - accuracy: 0.9778\n",
      "Epoch 4/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9667WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 365ms/step - loss: 0.0408 - accuracy: 0.9667\n",
      "Epoch 5/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 357ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 6/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 347ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 7/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 339ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 8/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 357ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 9/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 359ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 10/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 362ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 11/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 12/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 352ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 13/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 362ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 14/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 15/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 16/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 17/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 354ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 18/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.6315e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 8.6315e-04 - accuracy: 1.0000\n",
      "Epoch 19/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9667WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 0.0633 - accuracy: 0.9667\n",
      "Epoch 20/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 351ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 21/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 22/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 23/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 24/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 25/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 26/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.0594 - accuracy: 0.9889\n",
      "Epoch 27/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9889  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 0.0128 - accuracy: 0.9889\n",
      "Epoch 28/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9778WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0330 - accuracy: 0.9778\n",
      "Epoch 29/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 30/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 339ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 31/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 32/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 33/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 34/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 35/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.5337e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 348ms/step - loss: 9.5337e-04 - accuracy: 1.0000\n",
      "Epoch 36/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 366ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 38/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9889    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 366ms/step - loss: 0.0086 - accuracy: 0.9889\n",
      "Epoch 39/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 40/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 41/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.7660e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 7.7660e-04 - accuracy: 1.0000\n",
      "Epoch 42/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.0200 - accuracy: 0.9889\n",
      "Epoch 43/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9889    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 0.0111 - accuracy: 0.9889\n",
      "Epoch 44/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 45/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 46/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 47/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 48/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 49/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.3773e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 5.3773e-04 - accuracy: 1.0000\n",
      "Epoch 50/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 357ms/step - loss: 0.0171 - accuracy: 0.9889\n",
      "Epoch 51/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.3660e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 3.3660e-04 - accuracy: 1.0000\n",
      "Epoch 52/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 361ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 53/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.7256e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 4.7256e-04 - accuracy: 1.0000\n",
      "Epoch 54/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.0180e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 7.0180e-04 - accuracy: 1.0000\n",
      "Epoch 55/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 351ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 57/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 58/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.3794e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 5.3794e-04 - accuracy: 1.0000\n",
      "Epoch 59/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.2231e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 6.2231e-04 - accuracy: 1.0000\n",
      "Epoch 60/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 61/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.7293e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 5.7293e-04 - accuracy: 1.0000\n",
      "Epoch 62/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.8584e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 4.8584e-04 - accuracy: 1.0000\n",
      "Epoch 63/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.2461e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 4.2461e-04 - accuracy: 1.0000\n",
      "Epoch 64/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.1506e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 6.1506e-04 - accuracy: 1.0000\n",
      "Epoch 65/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 354ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 66/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.1277e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 3.1277e-04 - accuracy: 1.0000\n",
      "Epoch 67/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4250e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 1.4250e-04 - accuracy: 1.0000\n",
      "Epoch 68/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.9697e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 2.9697e-04 - accuracy: 1.0000\n",
      "Epoch 69/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6644e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 365ms/step - loss: 1.6644e-04 - accuracy: 1.0000\n",
      "Epoch 70/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5642e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 1.5642e-04 - accuracy: 1.0000\n",
      "Epoch 71/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.1138e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 8.1138e-04 - accuracy: 1.0000\n",
      "Epoch 72/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.0247e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 7.0247e-04 - accuracy: 1.0000\n",
      "Epoch 73/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.6350e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 2.6350e-04 - accuracy: 1.0000\n",
      "Epoch 74/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7840e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 1.7840e-04 - accuracy: 1.0000\n",
      "Epoch 75/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1501e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 1.1501e-04 - accuracy: 1.0000\n",
      "Epoch 76/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1230e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 2.1230e-04 - accuracy: 1.0000\n",
      "Epoch 77/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.8526e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 7.8526e-04 - accuracy: 1.0000\n",
      "Epoch 78/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5746e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 1.5746e-04 - accuracy: 1.0000\n",
      "Epoch 79/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.1738e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 4.1738e-05 - accuracy: 1.0000\n",
      "Epoch 80/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.5544e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 8.5544e-04 - accuracy: 1.0000\n",
      "Epoch 81/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8658e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 1.8658e-04 - accuracy: 1.0000\n",
      "Epoch 82/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8355e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 1.8355e-04 - accuracy: 1.0000\n",
      "Epoch 83/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 84/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7363e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 1.7363e-04 - accuracy: 1.0000\n",
      "Epoch 85/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.2049e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 8.2049e-05 - accuracy: 1.0000\n",
      "Epoch 86/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3029e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 339ms/step - loss: 2.3029e-04 - accuracy: 1.0000\n",
      "Epoch 87/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.4123e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 363ms/step - loss: 8.4123e-04 - accuracy: 1.0000\n",
      "Epoch 88/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1292e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 2.1292e-04 - accuracy: 1.0000\n",
      "Epoch 89/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2186e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 1.2186e-04 - accuracy: 1.0000\n",
      "Epoch 90/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2209e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 1.2209e-04 - accuracy: 1.0000\n",
      "Epoch 91/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.6221e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 2.6221e-04 - accuracy: 1.0000\n",
      "Epoch 92/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.3966e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 9.3966e-04 - accuracy: 1.0000\n",
      "Epoch 93/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.4549e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 339ms/step - loss: 7.4549e-04 - accuracy: 1.0000\n",
      "Epoch 94/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1312e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 2.1312e-04 - accuracy: 1.0000\n",
      "Epoch 95/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.2406e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 350ms/step - loss: 5.2406e-05 - accuracy: 1.0000\n",
      "Epoch 96/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3023e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 2.3023e-04 - accuracy: 1.0000\n",
      "Epoch 97/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6847e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 1.6847e-04 - accuracy: 1.0000\n",
      "Epoch 98/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4327e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 348ms/step - loss: 1.4327e-04 - accuracy: 1.0000\n",
      "Epoch 99/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0310e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 1.0310e-04 - accuracy: 1.0000\n",
      "Epoch 100/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.5074e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 6.5074e-05 - accuracy: 1.0000\n",
      "Epoch 101/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5427e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 350ms/step - loss: 1.5427e-04 - accuracy: 1.0000\n",
      "Epoch 102/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.1509e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 348ms/step - loss: 4.1509e-05 - accuracy: 1.0000\n",
      "Epoch 103/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.5533e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 3.5533e-04 - accuracy: 1.0000\n",
      "Epoch 104/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.4555e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 7.4555e-05 - accuracy: 1.0000\n",
      "Epoch 105/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.8307e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 8.8307e-04 - accuracy: 1.0000\n",
      "Epoch 106/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.3101e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 353ms/step - loss: 5.3101e-05 - accuracy: 1.0000\n",
      "Epoch 107/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.5520e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 6.5520e-05 - accuracy: 1.0000\n",
      "Epoch 108/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.0711e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 353ms/step - loss: 4.0711e-05 - accuracy: 1.0000\n",
      "Epoch 109/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.8341e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 2.8341e-05 - accuracy: 1.0000\n",
      "Epoch 110/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6864e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 358ms/step - loss: 1.6864e-04 - accuracy: 1.0000\n",
      "Epoch 111/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0516e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 1.0516e-04 - accuracy: 1.0000\n",
      "Epoch 112/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.0826e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 348ms/step - loss: 8.0826e-05 - accuracy: 1.0000\n",
      "Epoch 113/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0490e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 353ms/step - loss: 1.0490e-04 - accuracy: 1.0000\n",
      "Epoch 114/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5134e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 1.5134e-04 - accuracy: 1.0000\n",
      "Epoch 115/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6477e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 1.6477e-04 - accuracy: 1.0000\n",
      "Epoch 116/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.2437e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 9.2437e-05 - accuracy: 1.0000\n",
      "Epoch 117/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.1443e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 3.1443e-04 - accuracy: 1.0000\n",
      "Epoch 118/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 119/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8504e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 1.8504e-04 - accuracy: 1.0000\n",
      "Epoch 120/120\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1098e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 1s 346ms/step - loss: 1.1098e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "batch_size = 32\n",
    "epochs = 120\n",
    "\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    # validation_data=(X_test, y_test),\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    callbacks = [early_stopping],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      hotdog       0.33      0.20      0.25         5\n",
      "  not_hotdog       0.43      0.60      0.50         5\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.38      0.40      0.38        10\n",
      "weighted avg       0.38      0.40      0.38        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating network\n",
    "predictions = model.predict(x = X_test, batch_size = batch_size)\n",
    "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20fae13f3d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = 120\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 50, 3)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[0.9989292  0.00107077]]\n",
      "hotdog\n"
     ]
    }
   ],
   "source": [
    "# make predicition on new data\n",
    "image = cv2.imread('./test/3.jpg')\n",
    "op = image.copy()\n",
    "image = cv2.resize(image, (50, 50))\n",
    "\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "# make prediction on image\n",
    "preds = model.predict(image)\n",
    "print(preds)\n",
    "# # find the class label index with the largest corresponding probability\n",
    "i = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[i]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
